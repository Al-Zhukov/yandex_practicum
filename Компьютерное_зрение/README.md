# Отток клиентов банка
Нам доступны исторические данные о поведении клиентов и расторжении договоров с банком. 
Попробуем спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. 

**Описание данных** 

Признаки:
* RowNumber — индекс строки в данных
* CustomerId — уникальный идентификатор клиента
* Surname — фамилия
* CreditScore — кредитный рейтинг
* Geography — страна проживания
* Gender — пол
* Age — возраст
* Tenure — сколько лет человек является клиентом банка
* Balance — баланс на счёте
* NumOfProducts — количество продуктов банка, используемых клиентом
* HasCrCard — наличие кредитной карты
* IsActiveMember — активность клиента
* EstimatedSalary — предполагаемая зарплата

Целевой признак:
* Exited — факт ухода клиента

Попробуем построить модель с предельно большим значением *F1*-меры (ориентируемся на значение 0.59). Попробуем разные модели (дерево решений, случайный лес, логистическую регрессию) и разные способы борьбы с дисбалансом классов. Дополнительно будем отслежвать значение *AUC-ROC*.

---
## Что сделано
1. Проведена подготовка данных: проверка на дубликаты, обработка пропусков, кодирование категориальных признаков, масштабирование количественных признаков.
2. Работаем с задачей классификации в ситуации дисбаланса классов: положительный класс - 20% от выборки. Для моделей решающего дерева, случайного леса и логистической регрессии опробованы разные подходы борьбы с дисбалансом классов: взвешивание классов, upsampling, downsampling, подбор порога классификации. Лучшие результаты показал случайный лес с подбором порога классификации.
3. Для случайного леса сравнили качество предсказания при использовании One Hot Encoding|Ordinal Encoding, подборе порога классификации и подборе количества оценщиков. OHE оказался чуть лучше.
4. Проверили значимость признака, в котором были пропуски. Она оказалась низкой, поэтому попробовали переобучить модель на полных данных, но без этого признака. Это немного улучшило качество на валидационной выборке.
5. Опробовали на тестовой выборке три модели случайного леса - (1) обучение на train + использованием всех признаков + подбор порога классификации и количества оценщиков по валидационной выборке; (2) обучение на train + использование всех данных (отказ от малозначимого признака с пропусками) + подбор порога классификации и количества оценщиков по валидационной выборке; (3) обучение на train+valid + использование всех данных (отказ от малозначимого признака с пропусками) + использование порога классификации и количества оценщиков из модели (2). 
6. Лучший результат показала модель (1): случайный леса с OHE, использованием масштабирования данных и подбора порога классификации для борьбы с дисбалансом классов.
